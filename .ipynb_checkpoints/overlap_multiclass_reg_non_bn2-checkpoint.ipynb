{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T14:39:28.777545Z",
     "start_time": "2025-10-14T14:39:28.776068Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:39:34.044257Z",
     "start_time": "2025-10-14T14:39:34.041075Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy.ma as ma\n",
    "import pylab as pl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Set data format\n",
    "K.set_image_data_format('channels_first')\n",
    "print(K.backend(), K.image_data_format())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow channels_first\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:39:43.941528Z",
     "start_time": "2025-10-14T14:39:36.332133Z"
    }
   },
   "source": [
    "batch_size = 128\n",
    "samples_per_epoch = 10\n",
    "num_classes = 5\n",
    "epochs = 40\n",
    "class_names = [\"voip\", \"video\", \"file transfer\", \"chat\", \"browsing\"]\n",
    "\n",
    "height, width = 1500, 1500\n",
    "input_shape = (1500, 1500, 1)  # NHWC\n",
    "\n",
    "\n",
    "MODEL_NAME = \"overlap_multiclass_reg_non_bn\"\n",
    "PATH_PREFIX = \"datasets/\"\n",
    "dataset_file = os.path.join(PATH_PREFIX, \"file_vs_all_reg.npz\")\n",
    "dataset = np.load(dataset_file)\n",
    "\n",
    "x_train = dataset['x_train']\n",
    "y_train_true = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val_true = dataset['y_val']\n",
    "\n",
    "x_train = x_train.transpose(0, 2, 3, 1)  # from (samples, 1, H, W) -> (samples, H, W, 1)\n",
    "x_val = x_val.transpose(0, 2, 3, 1)\n",
    "\n",
    "print(x_train.shape, y_train_true.shape)\n",
    "print(x_val.shape, y_val_true.shape)\n",
    "\n",
    "# Shuffle data\n",
    "def shuffle_data(x, y):\n",
    "    s = np.arange(x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    return x[s], y[s]\n",
    "\n",
    "x_train, y_train_true = shuffle_data(x_train, y_train_true)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train_true, num_classes)\n",
    "y_val = to_categorical(y_val_true, num_classes)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1988, 1500, 1500, 1) (1988,)\n",
      "(221, 1500, 1500, 1) (221,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:39:54.519327Z",
     "start_time": "2025-10-14T14:39:51.123488Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Shuffle data\n",
    "def shuffle_data(x, y):\n",
    "    s = np.arange(x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    return x[s], y[s]\n",
    "\n",
    "x_train, y_train_true = shuffle_data(x_train, y_train_true)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train_true, num_classes)\n",
    "y_val = to_categorical(y_val_true, num_classes)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:39:59.418672Z",
     "start_time": "2025-10-14T14:39:56.072217Z"
    }
   },
   "source": [
    "def shuffle_data(x, y):\n",
    "    s = np.arange(x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x = x[s]\n",
    "    y = y[s]\n",
    "    print (x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train_true = shuffle_data(x_train, y_train_true)\n",
    "\n",
    "print(y_train_true[0:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1988, 1500, 1500, 1) (1988,)\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:40:00.840703Z",
     "start_time": "2025-10-14T14:40:00.835421Z"
    }
   },
   "source": [
    "y_train = to_categorical(y_train_true, num_classes)\n",
    "y_val =to_categorical(y_val_true, num_classes)\n",
    "print(y_train[0:10])\n",
    "print (y_val[0:10])\n",
    "print(y_train.shape, y_val.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "(1988, 5) (221, 5)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Compile model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:40:04.958999Z",
     "start_time": "2025-10-14T14:40:04.953845Z"
    }
   },
   "source": [
    "def precision(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define nice_imshow and make_moasic functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:40:07.742454Z",
     "start_time": "2025-10-14T14:40:07.630606Z"
    }
   },
   "source": [
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy.ma as ma\n",
    "\n",
    "def nice_imshow(ax, data, vmin=None, vmax=None, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.imshow\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = cm.jet\n",
    "    if vmin is None:\n",
    "        vmin = data.min()\n",
    "    if vmax is None:\n",
    "        vmax = data.max()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap,origin='lower')\n",
    "    if bar:\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        pl.colorbar(im, cax=cax)\n",
    "\n",
    "def plotNNFilter2(data, nrows, ncols, layer_name, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.subplot with color bar\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = \"gray\"\n",
    "    \n",
    "    fig, axes = pl.subplots(nrows, ncols,figsize=(5*ncols, 4*nrows))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        im = ax.imshow(data[:,:,i], interpolation=\"nearest\", cmap=cmap)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.05)\n",
    "    if bar:\n",
    "        fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "    \n",
    "    pl.savefig(MODEL_NAME +  \"_plotNNFilter2_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "\n",
    "def plotNNFilter(data, nrows, ncols, layer_name, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.subplot\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = \"gray\"\n",
    "    \n",
    "    pl.figure(figsize=(3*ncols, 3*nrows))\n",
    "    \n",
    "    for i in range(nrows*ncols):\n",
    "        pl.subplot(nrows, ncols, i+1)\n",
    "        pl.imshow(data[:,:,i], interpolation=\"nearest\", cmap=cmap)\n",
    "        pl.xticks([])\n",
    "        pl.yticks([])\n",
    "        pl.gca().invert_yaxis()\n",
    "    pl.subplots_adjust(wspace=0.025, hspace=0.05)\n",
    "    pl.savefig(MODEL_NAME +  \"_plotNNFilter_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "        \n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[2]\n",
    "    imshape = imgs.shape[0:2]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in range(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[:,:,i]\n",
    "    return mosaic\n",
    "\n",
    "def mosaic_imshow(imgs, nrows, ncols, cmap=None, border=1, layer_name=\"convout\"):\n",
    "    pl.figure(figsize=(3*ncols, 3*nrows))\n",
    "#     pl.suptitle('convout2')\n",
    "    nice_imshow(pl.gca(), make_mosaic(imgs, nrows, ncols, border=border), cmap=cmap)\n",
    "    pl.savefig(MODEL_NAME +  \"_mosaic_imshow_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "\n",
    "pl.imshow(make_mosaic(np.random.random((10, 10, 9)), 3, 3, border=1))\n",
    "pl.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:02:03.818214Z",
     "start_time": "2025-10-14T14:02:03.816726Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:40:14.234941Z",
     "start_time": "2025-10-14T14:40:14.022994Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "# Ensure your input shape matches your data\n",
    "input_shape = (1, 1500, 1500)  # channels_first\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(10, kernel_size=(10,10), strides=5, padding=\"same\", input_shape=input_shape, name=\"conv1\"),\n",
    "    Activation('relu', name=\"relu1\"),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(20, kernel_size=(10,10), strides=5, padding=\"same\", name=\"conv2\"),\n",
    "    Activation('relu', name=\"relu2\"),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', name=\"dense1\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax', name=\"output\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', top_2_categorical_accuracy, f1_score, precision, recall]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Visualize weights\n",
    "W1 = model.layers[0].get_weights()[0]\n",
    "W1 = np.squeeze(W1)\n",
    "# W1 = np.asarray(W1)\n",
    "print(\"W1 shape : \", W1.shape)\n",
    "\n",
    "mosaic_imshow(W1, 2, 5, cmap=cm.binary, border=1, layer_name=\"conv1_weights_before\")\n",
    "plotNNFilter(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights_before\")\n",
    "plotNNFilter2(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights_before\")\n",
    "\n",
    "# Visualize weights\n",
    "W2 = model.layers[3].get_weights()[0][:,:,0,:]\n",
    "W2 = np.asarray(W2)\n",
    "print(\"W2 shape : \", W2.shape)\n",
    "\n",
    "mosaic_imshow(W2, 4, 5, cmap=cm.binary, border=1, layer_name=\"conv2_weights_before\")\n",
    "plotNNFilter(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights_before\")\n",
    "plotNNFilter2(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights_before\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_2_categorical_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m      5\u001B[39m input_shape = (\u001B[32m1\u001B[39m, \u001B[32m1500\u001B[39m, \u001B[32m1500\u001B[39m)  \u001B[38;5;66;03m# channels_first\u001B[39;00m\n\u001B[32m      7\u001B[39m model = Sequential([\n\u001B[32m      8\u001B[39m     Conv2D(\u001B[32m10\u001B[39m, kernel_size=(\u001B[32m10\u001B[39m,\u001B[32m10\u001B[39m), strides=\u001B[32m5\u001B[39m, padding=\u001B[33m\"\u001B[39m\u001B[33msame\u001B[39m\u001B[33m\"\u001B[39m, input_shape=input_shape, name=\u001B[33m\"\u001B[39m\u001B[33mconv1\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m      9\u001B[39m     Activation(\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, name=\u001B[33m\"\u001B[39m\u001B[33mrelu1\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   (...)\u001B[39m\u001B[32m     20\u001B[39m     Dense(num_classes, activation=\u001B[33m'\u001B[39m\u001B[33msoftmax\u001B[39m\u001B[33m'\u001B[39m, name=\u001B[33m\"\u001B[39m\u001B[33moutput\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     21\u001B[39m ])\n\u001B[32m     24\u001B[39m model.compile(\n\u001B[32m     25\u001B[39m     loss=\u001B[33m'\u001B[39m\u001B[33mcategorical_crossentropy\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     26\u001B[39m     optimizer=\u001B[33m'\u001B[39m\u001B[33madam\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     metrics=[\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m, \u001B[43mtop_2_categorical_accuracy\u001B[49m, f1_score, precision, recall]\n\u001B[32m     28\u001B[39m )\n\u001B[32m     30\u001B[39m model.summary()\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Visualize weights\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'top_2_categorical_accuracy' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:11:52.028839Z",
     "start_time": "2025-10-14T14:11:51.161512Z"
    }
   },
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "def generator(features, labels, batch_size):\n",
    "    num_samples = len(features)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_x = features[offset:offset+batch_size].astype(np.float32)\n",
    "            batch_y = labels[offset:offset+batch_size].astype(np.float32)\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "# Callbacks\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./Graph',\n",
    "    histogram_freq=1,\n",
    "    write_images=True\n",
    ")\n",
    "\n",
    "checkpointer_loss = ModelCheckpoint(\n",
    "    filepath=MODEL_NAME + '_loss.weights.h5',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "checkpointer_acc = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    filepath=MODEL_NAME + '_acc.weights.h5',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    generator(x_train, y_train, batch_size),\n",
    "    steps_per_epoch=len(x_train)//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard, checkpointer_loss, checkpointer_acc],\n",
    "    validation_data=(x_val.astype(np.float32), y_val.astype(np.float32))\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001B[1mInput 0 of layer \"conv1\" is incompatible with the layer: expected axis 1 of input shape to have value 1, but received input with shape (None, 1500, 1500, 1)\u001B[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 1500, 1500, 1), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[63]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     24\u001B[39m checkpointer_acc = ModelCheckpoint(\n\u001B[32m     25\u001B[39m     monitor=\u001B[33m'\u001B[39m\u001B[33mval_accuracy\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     26\u001B[39m     filepath=MODEL_NAME + \u001B[33m'\u001B[39m\u001B[33m_acc.weights.h5\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     29\u001B[39m     save_weights_only=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     30\u001B[39m )\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m history = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m/\u001B[49m\u001B[43m/\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtensorboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpointer_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpointer_acc\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m.\u001B[49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m.\u001B[49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/input_spec.py:227\u001B[39m, in \u001B[36massert_input_compatibility\u001B[39m\u001B[34m(input_spec, inputs, layer_name)\u001B[39m\n\u001B[32m    222\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m axis, value \u001B[38;5;129;01min\u001B[39;00m spec.axes.items():\n\u001B[32m    223\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m shape[axis] \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\n\u001B[32m    224\u001B[39m             value,\n\u001B[32m    225\u001B[39m             \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    226\u001B[39m         }:\n\u001B[32m--> \u001B[39m\u001B[32m227\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    228\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m of layer \u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m is \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    229\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mincompatible with the layer: expected axis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    230\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mof input shape to have value \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    231\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mbut received input with \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    232\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mshape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    233\u001B[39m             )\n\u001B[32m    234\u001B[39m \u001B[38;5;66;03m# Check shape.\u001B[39;00m\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m spec.shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mValueError\u001B[39m: Exception encountered when calling Sequential.call().\n\n\u001B[1mInput 0 of layer \"conv1\" is incompatible with the layer: expected axis 1 of input shape to have value 1, but received input with shape (None, 1500, 1500, 1)\u001B[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 1500, 1500, 1), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot history accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpickle\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[43mMODEL_NAME\u001B[49m +  \u001B[33m\"\u001B[39m\u001B[33m_accuracy.pkl\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m output:\n\u001B[32m      5\u001B[39m     pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# list all data in history\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'MODEL_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(MODEL_NAME +  \"_accuracy.pkl\", 'wb') as output:\n",
    "    pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "x = np.asarray(range(1,epochs + 1))\n",
    "# summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.plot(x, history.history['acc'])\n",
    "plt.plot(x, history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(MODEL_NAME +  \" accuracy history\", bbox_inches='tight', pad_inches=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m y_val_prediction = \u001B[43mmodel\u001B[49m.predict_classes(x_val, verbose=\u001B[32m1\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_val_prediction = model.predict_classes(x_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43my_val_prediction\u001B[49m[:\u001B[32m10\u001B[39m])\n",
      "\u001B[31mNameError\u001B[39m: name 'y_val_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_val_prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 46\u001B[39m\n\u001B[32m     43\u001B[39m     plt.savefig(fname, bbox_inches=\u001B[33m'\u001B[39m\u001B[33mtight\u001B[39m\u001B[33m'\u001B[39m, pad_inches=\u001B[32m1\u001B[39m)\n\u001B[32m     45\u001B[39m \u001B[38;5;66;03m# Compute confusion matrix\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m cnf_matrix = confusion_matrix(\u001B[43my_val_true\u001B[49m, y_val_prediction)\n\u001B[32m     47\u001B[39m np.set_printoptions(precision=\u001B[32m2\u001B[39m)\n\u001B[32m     49\u001B[39m \u001B[38;5;66;03m# Plot non-normalized confusion matrix\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'y_val_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          fname='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, format(cm[i, j]*100, fmt) + '%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")    \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_val_true, y_val_prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization',\n",
    "                      fname=MODEL_NAME + \"_\" + 'Confusion_matrix_without_normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix',\n",
    "                      fname=MODEL_NAME + \"_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y_true, y_pred):\n",
    "    correct = sum([1 for i,pred in enumerate(y_pred) if y_true[i][pred]==1])\n",
    "    print(y_true.shape[0], correct, correct*1.0/len(y_true))\n",
    "    \n",
    "    for class_ind in range(y_true.shape[1]):\n",
    "        total_ind = len([1 for val in y_true if val[class_ind]==1])\n",
    "        correct_ind = sum([1 for i,pred in enumerate(y_pred) if (pred == class_ind and y_true[i][pred]==1)])\n",
    "        print(class_ind, total_ind, correct_ind, correct_ind*1.0/total_ind)\n",
    "\n",
    "stats(y_val, y_val_prediction)\n",
    "# stats(y_test_vpn, y_test_vpn_prediction)\n",
    "# stats(y_test_tor, y_test_tor_prediction)\n",
    "# correct_1 = sum([1 for i,pred in enumerate(y_test_prediction) if (pred == 1 and y_test[i][pred]==1)])\n",
    "# print correct_1, correct_1*1.0/len([1 for val in y_test if val[1]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val_true, y_val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first layer of convolutions on an input image\n",
    "X = x_train[i][0]\n",
    "print(X)\n",
    "print(y_train_true[i])\n",
    "pl.figure(figsize=(15, 15))\n",
    "nice_imshow(pl.gca(), np.squeeze(X), vmin=0, vmax=1, cmap=cm.binary)\n",
    "pl.savefig(MODEL_NAME +  \"_input_\" + str(int(y_train_true[i])), bbox_inches='tight', pad_inches=1)\n",
    "pl.show()\n",
    "\n",
    "# Visualize convolution result (after activation)\n",
    "def get_layer_output(layer, input_img, layer_name):\n",
    "    convout_f = K.function(model.inputs, [layer.output])\n",
    "    C = convout_f([input_img])\n",
    "    C = np.squeeze(C)\n",
    "    print(layer_name + \" output shape : \", C.shape)\n",
    "    C = np.transpose(C)\n",
    "    C = np.swapaxes(C,0,1)\n",
    "    print(layer_name + \" output shape : \", C.shape)\n",
    "    return C\n",
    "\n",
    "\n",
    "C1 = get_layer_output(convout1, x_train[i:i+1], layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "mosaic_imshow(C1, 2, 5, cmap=cm.binary, border=2, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "plotNNFilter(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "plotNNFilter2(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "\n",
    "C2 = get_layer_output(convout2, x_train[i:i+1], layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "mosaic_imshow(C2, 4, 5, cmap=cm.binary, border=2, layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "plotNNFilter(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "plotNNFilter2(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_\" + str(int(y_train_true[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weights\n",
    "W1 = model.layers[0].get_weights()[0]\n",
    "W1 = np.squeeze(W1)\n",
    "# W1 = np.asarray(W1)\n",
    "print(\"W1 shape : \", W1.shape)\n",
    "\n",
    "mosaic_imshow(W1, 2, 5, cmap=cm.binary, border=1, layer_name=\"conv1_weights\")\n",
    "plotNNFilter(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights\")\n",
    "plotNNFilter2(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights\")\n",
    "\n",
    "# Visualize weights\n",
    "W2 = model.layers[3].get_weights()[0][:,:,0,:]\n",
    "W2 = np.asarray(W2)\n",
    "print(\"W2 shape : \", W2.shape)\n",
    "\n",
    "mosaic_imshow(W2, 4, 5, cmap=cm.binary, border=1, layer_name=\"conv2_weights\")\n",
    "plotNNFilter(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights\")\n",
    "plotNNFilter2(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true, y_val_prediction\n",
    "\n",
    "for j in range(len(y_val_true)):\n",
    "    if y_val_true[j] == 0 and y_val_prediction[j] == 1:\n",
    "        print(j, sum(sum(sum(x_val[j]))))\n",
    "#         pl.figure(figsize=(10, 10))\n",
    "#         pl.title('input ' + str(j))\n",
    "#         nice_imshow(pl.gca(), np.squeeze(x_val[j]), vmin=0, vmax=1, cmap=cm.binary)\n",
    "#         pl.savefig(MODEL_NAME +  \"_input\", bbox_inches='tight', pad_inches=1)\n",
    "#         pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vpn = np.load(PATH_PREFIX + \"vpn_x_test.npy\")\n",
    "y_test_vpn_true = np.load(PATH_PREFIX + \"vpn_y_test.npy\")\n",
    "x_test_tor = np.load(PATH_PREFIX + \"tor_x_test.npy\")\n",
    "y_test_tor_true = np.load(PATH_PREFIX + \"tor_y_test.npy\")\n",
    "\n",
    "y_test_vpn =to_categorical(y_test_vpn_true, num_classes)\n",
    "y_test_tor =to_categorical(y_test_tor_true, num_classes)\n",
    "\n",
    "print(x_test_vpn.shape, y_test_vpn.shape)\n",
    "print(x_test_tor.shape, y_test_tor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(MODEL_NAME + '.hdf5')\n",
    "\n",
    "score_val = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('Validation loss:', score_val[0])\n",
    "print('Validaion accuracy:', score_val[1])\n",
    "print('Validaion top_2_categorical_accuracy:', score_val[2])\n",
    "\n",
    "score_vpn = model.evaluate(x_test_vpn, y_test_vpn, verbose=1)\n",
    "print('VPN_Test loss:', score_vpn[0])\n",
    "print('VPN_Test accuracy:', score_vpn[1])\n",
    "print('VPN_Test top_2_categorical_accuracy:', score_vpn[2])\n",
    "\n",
    "score_tor = model.evaluate(x_test_tor, y_test_tor, verbose=1)\n",
    "print('TOR_Test loss:', score_tor[0])\n",
    "print('TOR_Test accuracy:', score_tor[1])\n",
    "print('TOR_Test top_2_categorical_accuracy:', score_tor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_vpn_prediction = model.predict_classes(x_test_vpn, verbose=1)\n",
    "y_test_tor_prediction = model.predict_classes(x_test_tor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_val = confusion_matrix(y_val_true, y_val_prediction)\n",
    "cnf_matrix_vpn = confusion_matrix(y_test_vpn_true, y_test_vpn_prediction)\n",
    "cnf_matrix_tor = confusion_matrix(y_test_tor_true, y_test_tor_prediction)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_val, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for regular validation set',\n",
    "                      fname=MODEL_NAME + \"_val_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_vpn, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for vpn test set',\n",
    "                      fname=MODEL_NAME + \"_test_vpn_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tor, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for tor test set',\n",
    "                      fname=MODEL_NAME + \"_test_tor_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(MODEL_NAME + '.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(MODEL_NAME + '.h5')\n",
    "print(\"Save Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
